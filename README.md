# LBPOâ€‘Studio (Layerâ€‘Based Prompt Optimizer)

**Outcomeâ€‘First Prompt Engineering â€” Spec â†’ Tests â†’ Score â†’ Argmax**  
KPI Cards Â· Version Evolution (Î”Accuracy) Â· Multiâ€‘chart Dashboard Â· i18nâ€‘ready UI Â· Oneâ€‘click Export

---

## What is LBPOâ€‘Studio?
LBPOâ€‘Studio is an outcomeâ€‘first, layerâ€‘based prompt optimizer. You define the **task specification** and **test cases**; the system then **searches**, **tests**, and **optimizes** prompts so the model steadily approaches the **ideal output you define**. It replaces â€œprompting by vibeâ€ with evidenceâ€‘backed iteration.

### Why it matters
- **Evidence over intuition** â€” Quality is measured with tests and KPIs, not gut feel.  
- **Outcomeâ€‘first** â€” Aligns generation with your target result and acceptance criteria.  
- **Reusable pipeline** â€” Templated Specs, Tests, KPIs, and Version Evolution logs.

---

## Core Features
- **Prompt Enhancer** â€” Structures intent, injects CoT when the task requires reasoning, supports parameterized placeholders.
- **Validator & Metrics** â€” Accuracy, F1, Pass Rate, Token Cost, and Progress; extensible scoring.
- **Version Evolution** â€” Records each change and its **Î”Accuracy** contribution.
- **Visualizationâ€‘First Dashboard** â€” Line/Bar/Pie/Gauge charts with consistent legends and units.
- **Oneâ€‘click Export** â€” Share results as Markdown, PDF, or PPTX with evidence and notes.
- **i18nâ€‘ready UI** â€” Language switching architecture; prioritize effective languages first.

---

## Architecture
```
UI (Vercel)  â†’  API (Render)  â†’  Evaluator  â†’  Metrics Store  â†’  KPI Dashboard
       â†‘              â†“                â†“               â†‘
   Prompt Enhancer â†’ Candidate Generation â†’ Scoring â†’ Version Evolution
```

- **Enhancer** converts user intent into structured prompts and can autoâ€‘enable CoT for reasoning tasks.  
- **Evaluator** runs test cases and emits scores (Accuracy, F1, etc.).  
- **Dashboard** displays KPI cards, charts, and the version evolution timeline.

---

## Project Structure
```
LBPO-Studio/
â”œâ”€ frontend/        # React/Vite (or similar) UI
â”œâ”€ backend/         # Node/Express (or similar) API & evaluator
â””â”€ others/          # Docs, diagrams, samples, scripts
```
**Demo mode**: static UI preview (`index.html` can be opened directly).  
**Cloud mode**: split frontend/backed; deploy frontend on Vercel and backend on Render.

---

## Quickstart

### A) Demo (Static UI)
1. Download the demo package and open `index.html` in your browser.  
2. Load the sample **Spec** and **Tests** to preview the workflow.  
3. KPI cards and charts render placeholders until linked to backend data.

### B) Cloud (Vercel + Render)

**Backend**
```bash
cd backend
cp .env.example .env
# Add your keys: OPENAI_API_KEY (and optionally ANTHROPIC_API_KEY, GEMINI_API_KEY)
# If using a database: DATABASE_URL
npm install
npm run dev   # or: npm run start
```

**Frontend**
```bash
cd frontend
npm install
npm run dev   # set BACKEND_BASE_URL in your .env (e.g., http://localhost:10000)
```

**Deploy**
- **Vercel (Frontend)**: import repo â†’ set `VITE_API_BASE` â†’ deploy.  
- **Render (Backend)**: add environment variables â†’ rely on platform `$PORT` â†’ deploy.

---

## Environment Variables
```
# Common
NODE_ENV=production
PORT=           # use the platform-injected PORT on Render

# Providers (pick what you use)
OPENAI_API_KEY=...
ANTHROPIC_API_KEY=...
GEMINI_API_KEY=...

# Optional
DATABASE_URL=...
JWT_SECRET=...
METRICS_WRITE_KEY=...
VITE_API_BASE=https://your-backend.onrender.com
```

---

## Usage Flow
1. **Define Spec** â€” Goal, constraints, quality bar, and tolerances.  
2. **Write Tests** â€” A compact but representative set with gold answers.  
3. **Run Optimize** â€” LBPOâ€‘Studio explores prompts/parameters and scores them automatically.  
4. **Review Evidence** â€” Inspect KPI cards, trend charts, and the Î”Accuracy evolution timeline.  
5. **Export & Share** â€” Package the winning prompt and evidence as Markdown/PDF/PPTX.

---

## KPIs
- Accuracy Â· F1 Â· Pass Rate Â· Token Cost Â· Progress%  
- Optional: A/B comparisons and costâ€‘quality tradeâ€‘off plots.

---

## Roadmap
- **v0.4** â€” Visualization dashboard, Version Evolution, i18n (effective languages first).  
- **v0.5** â€” Data binding and oneâ€‘click exports (MD/PDF/PPTX).  
- **v0.6** â€” A/B testing, team collaboration, and audit trails.

---

## Contributing
Issues and PRs are welcome. Please include a minimal repro and screenshots/screencasts.


## ğŸªª License
Â© 2025 Tiger â€” Released under the MIT License.  
Attribution is appreciated but not required.  
This project embodies an open-source spirit â€” designed to inspire and evolve through collective creativity.  

## Acknowledgments
Lucide icons Â· Inter font Â· Vercel Â· Render. Thanks to early users and reviewers!
